<!DOCTYPE html>
<html>
 <head>
  <meta charset="utf-8"/>
  <meta content="width=device-width, initial-scale=1.0" name="viewport"/>
  <meta content="Docutils 0.17.1: http://docutils.sourceforge.net/" name="generator"/>
  <meta content="width=device-width,initial-scale=1" name="viewport"/>
  <meta content="ie=edge" http-equiv="x-ua-compatible"/>
  <meta content="Copy to clipboard" name="lang:clipboard.copy"/>
  <meta content="Copied to clipboard" name="lang:clipboard.copied"/>
  <meta content="en" name="lang:search.language"/>
  <meta content="True" name="lang:search.pipeline.stopwords"/>
  <meta content="True" name="lang:search.pipeline.trimmer"/>
  <meta content="No matching documents" name="lang:search.result.none"/>
  <meta content="1 matching document" name="lang:search.result.one"/>
  <meta content="# matching documents" name="lang:search.result.other"/>
  <meta content="[\s\-]+" name="lang:search.tokenizer"/>
  <link crossorigin="" href="https://fonts.gstatic.com/" rel="preconnect"/>
  <link href="https://fonts.googleapis.com/css?family=Roboto+Mono:400,500,700|Roboto:300,400,400i,700&amp;display=fallback" rel="stylesheet"/>
  <style>
   body,
      input {
        font-family: "Roboto", "Helvetica Neue", Helvetica, Arial, sans-serif
      }

      code,
      kbd,
      pre {
        font-family: "Roboto Mono", "Courier New", Courier, monospace
      }
  </style>
  <link href="../_static/stylesheets/application.css" rel="stylesheet"/>
  <link href="../_static/stylesheets/application-palette.css" rel="stylesheet"/>
  <link href="../_static/stylesheets/application-fixes.css" rel="stylesheet"/>
  <link href="../_static/fonts/material-icons.css" rel="stylesheet"/>
  <meta content="84bd00" name="theme-color"/>
  <script src="../_static/javascripts/modernizr.js">
  </script>
  <title>
   trtorch — TRTorch master documentation
  </title>
  <link href="../_static/material.css" rel="stylesheet" type="text/css"/>
  <link href="../_static/pygments.css" rel="stylesheet" type="text/css"/>
  <link href="../_static/collapsible-lists/css/tree_view.css" rel="stylesheet" type="text/css"/>
  <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js">
  </script>
  <script src="../_static/jquery.js">
  </script>
  <script src="../_static/underscore.js">
  </script>
  <script src="../_static/doctools.js">
  </script>
  <script src="../_static/language_data.js">
  </script>
  <script src="../_static/collapsible-lists/js/CollapsibleLists.compressed.js">
  </script>
  <script src="../_static/collapsible-lists/js/apply-collapsible-lists.js">
  </script>
  <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js">
  </script>
  <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS-MML_HTMLorMML">
  </script>
  <script type="text/x-mathjax-config">
   MathJax.Hub.Config({"tex2jax": {"inlineMath": [["$", "$"], ["\\(", "\\)"]], "processEscapes": true, "ignoreClass": "document", "processClass": "math|output_area"}})
  </script>
  <link href="../genindex.html" rel="index" title="Index"/>
  <link href="../search.html" rel="search" title="Search"/>
  <link href="logging.html" rel="next" title="trtorch.logging"/>
  <link href="../_notebooks/vgg-qat.html" rel="prev" title="Deploying Quantization Aware Trained models in INT8 using TRTorch"/>
 </head>
 <body data-md-color-accent="light-green" data-md-color-primary="light-green" dir="ltr">
  <svg class="md-svg">
   <defs data-children-count="0">
    <svg height="448" id="__github" viewbox="0 0 416 448" width="416" xmlns="http://www.w3.org/2000/svg">
     <path d="M160 304q0 10-3.125 20.5t-10.75 19T128 352t-18.125-8.5-10.75-19T96 304t3.125-20.5 10.75-19T128 256t18.125 8.5 10.75 19T160 304zm160 0q0 10-3.125 20.5t-10.75 19T288 352t-18.125-8.5-10.75-19T256 304t3.125-20.5 10.75-19T288 256t18.125 8.5 10.75 19T320 304zm40 0q0-30-17.25-51T296 232q-10.25 0-48.75 5.25Q229.5 240 208 240t-39.25-2.75Q130.75 232 120 232q-29.5 0-46.75 21T56 304q0 22 8 38.375t20.25 25.75 30.5 15 35 7.375 37.25 1.75h42q20.5 0 37.25-1.75t35-7.375 30.5-15 20.25-25.75T360 304zm56-44q0 51.75-15.25 82.75-9.5 19.25-26.375 33.25t-35.25 21.5-42.5 11.875-42.875 5.5T212 416q-19.5 0-35.5-.75t-36.875-3.125-38.125-7.5-34.25-12.875T37 371.5t-21.5-28.75Q0 312 0 260q0-59.25 34-99-6.75-20.5-6.75-42.5 0-29 12.75-54.5 27 0 47.5 9.875t47.25 30.875Q171.5 96 212 96q37 0 70 8 26.25-20.5 46.75-30.25T376 64q12.75 25.5 12.75 54.5 0 21.75-6.75 42 34 40 34 99.5z" fill="currentColor">
     </path>
    </svg>
   </defs>
  </svg>
  <input class="md-toggle" data-md-toggle="drawer" id="__drawer" type="checkbox"/>
  <input class="md-toggle" data-md-toggle="search" id="__search" type="checkbox"/>
  <label class="md-overlay" data-md-component="overlay" for="__drawer">
  </label>
  <a class="md-skip" href="#py_api/trtorch" tabindex="1">
   Skip to content
  </a>
  <header class="md-header" data-md-component="header">
   <nav class="md-header-nav md-grid">
    <div class="md-flex navheader">
     <div class="md-flex__cell md-flex__cell--shrink">
      <a class="md-header-nav__button md-logo" href="../index.html" title="TRTorch master documentation">
       <i class="md-icon">
        
       </i>
      </a>
     </div>
     <div class="md-flex__cell md-flex__cell--shrink">
      <label class="md-icon md-icon--menu md-header-nav__button" for="__drawer">
      </label>
     </div>
     <div class="md-flex__cell md-flex__cell--stretch">
      <div class="md-flex__ellipsis md-header-nav__title" data-md-component="title">
       <span class="md-header-nav__topic">
        TRTorch
       </span>
       <span class="md-header-nav__topic">
        trtorch
       </span>
      </div>
     </div>
     <div class="md-flex__cell md-flex__cell--shrink">
      <label class="md-icon md-icon--search md-header-nav__button" for="__search">
      </label>
      <div class="md-search" data-md-component="search" role="dialog">
       <label class="md-search__overlay" for="__search">
       </label>
       <div class="md-search__inner" role="search">
        <form action="../search.html" class="md-search__form" method="get" name="search">
         <input autocapitalize="off" autocomplete="off" class="md-search__input" data-md-component="query" data-md-state="active" name="q" placeholder="Search" spellcheck="false" type="text"/>
         <label class="md-icon md-search__icon" for="__search">
         </label>
         <button class="md-icon md-search__icon" data-md-component="reset" tabindex="-1" type="reset">
          
         </button>
        </form>
        <div class="md-search__output">
         <div class="md-search__scrollwrap" data-md-scrollfix="">
          <div class="md-search-result" data-md-component="result">
           <div class="md-search-result__meta">
            Type to start searching
           </div>
           <ol class="md-search-result__list">
           </ol>
          </div>
         </div>
        </div>
       </div>
      </div>
     </div>
     <div class="md-flex__cell md-flex__cell--shrink">
      <div class="md-header-nav__source">
       <a class="md-source" data-md-source="github" href="https://github.com/nvidia/TRTorch/" title="Go to repository">
        <div class="md-source__icon">
         <svg height="28" viewbox="0 0 24 24" width="28" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink">
          <use height="24" width="24" xlink:href="#__github">
          </use>
         </svg>
        </div>
        <div class="md-source__repository">
         TRTorch
        </div>
       </a>
      </div>
     </div>
     <div class="md-flex__cell md-flex__cell--shrink dropdown">
      <button class="dropdownbutton">
       Versions
      </button>
      <div class="dropdown-content md-hero">
       <a href="https://nvidia.github.io/TRTorch/" title="master">
        master
       </a>
       <a href="https://nvidia.github.io/TRTorch/v0.4.1/" title="v0.4.1">
        v0.4.1
       </a>
       <a href="https://nvidia.github.io/TRTorch/v0.4.0/" title="v0.4.0">
        v0.4.0
       </a>
       <a href="https://nvidia.github.io/TRTorch/v0.3.0/" title="v0.3.0">
        v0.3.0
       </a>
       <a href="https://nvidia.github.io/TRTorch/v0.2.0/" title="v0.2.0">
        v0.2.0
       </a>
       <a href="https://nvidia.github.io/TRTorch/v0.1.0/" title="v0.1.0">
        v0.1.0
       </a>
       <a href="https://nvidia.github.io/TRTorch/v0.0.3/" title="v0.0.3">
        v0.0.3
       </a>
       <a href="https://nvidia.github.io/TRTorch/v0.0.2/" title="v0.0.2">
        v0.0.2
       </a>
       <a href="https://nvidia.github.io/TRTorch/v0.0.1/" title="v0.0.1">
        v0.0.1
       </a>
      </div>
     </div>
    </div>
   </nav>
  </header>
  <div class="md-container">
   <nav class="md-tabs" data-md-component="tabs">
    <div class="md-tabs__inner md-grid">
     <ul class="md-tabs__list">
      <li class="md-tabs__item">
       <a class="md-tabs__link" href="../index.html">
        TRTorch master documentation
       </a>
      </li>
     </ul>
    </div>
   </nav>
   <main class="md-main">
    <div class="md-main__inner md-grid" data-md-component="container">
     <div class="md-sidebar md-sidebar--primary" data-md-component="navigation">
      <div class="md-sidebar__scrollwrap">
       <div class="md-sidebar__inner">
        <nav class="md-nav md-nav--primary" data-md-level="0">
         <label class="md-nav__title md-nav__title--site" for="__drawer">
          <a class="md-nav__button md-logo" href="../index.html" title="TRTorch master documentation">
           <i class="md-icon">
            
           </i>
          </a>
          <a href="../index.html" title="TRTorch master documentation">
           TRTorch
          </a>
         </label>
         <div class="md-nav__source">
          <a class="md-source" data-md-source="github" href="https://github.com/nvidia/TRTorch/" title="Go to repository">
           <div class="md-source__icon">
            <svg height="28" viewbox="0 0 24 24" width="28" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink">
             <use height="24" width="24" xlink:href="#__github">
             </use>
            </svg>
           </div>
           <div class="md-source__repository">
            TRTorch
           </div>
          </a>
         </div>
         <ul class="md-nav__list">
          <li class="md-nav__item">
           <span class="md-nav__link caption">
            <span class="caption-text">
             Getting Started
            </span>
           </span>
          </li>
          <li class="md-nav__item">
           <a class="md-nav__link" href="../tutorials/installation.html">
            Installation
           </a>
          </li>
          <li class="md-nav__item">
           <a class="md-nav__link" href="../tutorials/getting_started.html">
            Getting Started
           </a>
          </li>
          <li class="md-nav__item">
           <a class="md-nav__link" href="../tutorials/ptq.html">
            Post Training Quantization (PTQ)
           </a>
          </li>
          <li class="md-nav__item">
           <a class="md-nav__link" href="../tutorials/trtorchc.html">
            trtorchc
           </a>
          </li>
          <li class="md-nav__item">
           <a class="md-nav__link" href="../tutorials/use_from_pytorch.html">
            Using TRTorch Directly From PyTorch
           </a>
          </li>
          <li class="md-nav__item">
           <a class="md-nav__link" href="../tutorials/runtime.html">
            Deploying TRTorch Programs
           </a>
          </li>
          <li class="md-nav__item">
           <a class="md-nav__link" href="../tutorials/using_dla.html">
            DLA
           </a>
          </li>
          <li class="md-nav__item">
           <span class="md-nav__link caption">
            <span class="caption-text">
             Notebooks
            </span>
           </span>
          </li>
          <li class="md-nav__item">
           <a class="md-nav__link" href="../_notebooks/lenet-getting-started.html">
            TRTorch Getting Started - LeNet
           </a>
          </li>
          <li class="md-nav__item">
           <a class="md-nav__link" href="../_notebooks/ssd-object-detection-demo.html">
            Object Detection with TRTorch (SSD)
           </a>
          </li>
          <li class="md-nav__item">
           <a class="md-nav__link" href="../_notebooks/vgg-qat.html">
            Deploying Quantization Aware Trained models in INT8 using TRTorch
           </a>
          </li>
          <li class="md-nav__item">
           <span class="md-nav__link caption">
            <span class="caption-text">
             Python API Documenation
            </span>
           </span>
          </li>
          <li class="md-nav__item">
           <input class="md-toggle md-nav__toggle" data-md-toggle="toc" id="__toc" type="checkbox"/>
           <label class="md-nav__link md-nav__link--active" for="__toc">
            trtorch
           </label>
           <a class="md-nav__link md-nav__link--active" href="#">
            trtorch
           </a>
           <nav class="md-nav md-nav--secondary">
            <label class="md-nav__title" for="__toc">
             Contents
            </label>
            <ul class="md-nav__list" data-md-scrollfix="">
             <li class="md-nav__item">
              <a class="md-nav__link" href="#py-api-trtorch--page-root">
               trtorch
              </a>
              <nav class="md-nav">
               <ul class="md-nav__list">
                <li class="md-nav__item">
                 <a class="md-nav__link" href="#functions">
                  Functions
                 </a>
                </li>
                <li class="md-nav__item">
                 <a class="md-nav__link" href="#classes">
                  Classes
                 </a>
                </li>
                <li class="md-nav__item">
                 <a class="md-nav__link" href="#enums">
                  Enums
                 </a>
                </li>
                <li class="md-nav__item">
                 <a class="md-nav__link" href="#submodules">
                  Submodules
                 </a>
                </li>
               </ul>
              </nav>
             </li>
             <li class="md-nav__item">
              <a class="md-nav__extra_link" href="../_sources/py_api/trtorch.rst.txt">
               Show Source
              </a>
             </li>
            </ul>
           </nav>
          </li>
          <li class="md-nav__item">
           <a class="md-nav__link" href="logging.html">
            trtorch.logging
           </a>
          </li>
          <li class="md-nav__item">
           <span class="md-nav__link caption">
            <span class="caption-text">
             C++ API Documenation
            </span>
           </span>
          </li>
          <li class="md-nav__item">
           <a class="md-nav__link" href="../_cpp_api/trtorch_cpp.html">
            TRTorch C++ API
           </a>
          </li>
          <li class="md-nav__item">
           <span class="md-nav__link caption">
            <span class="caption-text">
             Contributor Documentation
            </span>
           </span>
          </li>
          <li class="md-nav__item">
           <a class="md-nav__link" href="../contributors/system_overview.html">
            System Overview
           </a>
          </li>
          <li class="md-nav__item">
           <a class="md-nav__link" href="../contributors/writing_converters.html">
            Writing Converters
           </a>
          </li>
          <li class="md-nav__item">
           <a class="md-nav__link" href="../contributors/useful_links.html">
            Useful Links for TRTorch Development
           </a>
          </li>
          <li class="md-nav__item">
           <span class="md-nav__link caption">
            <span class="caption-text">
             Indices
            </span>
           </span>
          </li>
          <li class="md-nav__item">
           <a class="md-nav__link" href="../indices/supported_ops.html">
            Operators Supported
           </a>
          </li>
         </ul>
        </nav>
       </div>
      </div>
     </div>
     <div class="md-sidebar md-sidebar--secondary" data-md-component="toc">
      <div class="md-sidebar__scrollwrap">
       <div class="md-sidebar__inner">
        <nav class="md-nav md-nav--secondary">
         <label class="md-nav__title" for="__toc">
          Contents
         </label>
         <ul class="md-nav__list" data-md-scrollfix="">
          <li class="md-nav__item">
           <a class="md-nav__link" href="#py-api-trtorch--page-root">
            trtorch
           </a>
           <nav class="md-nav">
            <ul class="md-nav__list">
             <li class="md-nav__item">
              <a class="md-nav__link" href="#functions">
               Functions
              </a>
             </li>
             <li class="md-nav__item">
              <a class="md-nav__link" href="#classes">
               Classes
              </a>
             </li>
             <li class="md-nav__item">
              <a class="md-nav__link" href="#enums">
               Enums
              </a>
             </li>
             <li class="md-nav__item">
              <a class="md-nav__link" href="#submodules">
               Submodules
              </a>
             </li>
            </ul>
           </nav>
          </li>
          <li class="md-nav__item">
           <a class="md-nav__extra_link" href="../_sources/py_api/trtorch.rst.txt">
            Show Source
           </a>
          </li>
          <li class="md-nav__item" id="searchbox">
          </li>
         </ul>
        </nav>
       </div>
      </div>
     </div>
     <div class="md-content">
      <article class="md-content__inner md-typeset" role="main">
       <span class="target" id="trtorch-py">
       </span>
       <section id="module-trtorch">
        <span id="trtorch">
        </span>
        <h1 id="py-api-trtorch--page-root">
         trtorch
         <a class="headerlink" href="#py-api-trtorch--page-root" title="Permalink to this headline">
          ¶
         </a>
        </h1>
        <section id="functions">
         <h2 id="functions">
          Functions
          <a class="headerlink" href="#functions" title="Permalink to this headline">
           ¶
          </a>
         </h2>
         <dl class="py function">
          <dt id="trtorch.set_device">
           <code class="sig-prename descclassname">
            trtorch.
           </code>
           <code class="sig-name descname">
            set_device
           </code>
           <span class="sig-paren">
            (
           </span>
           <em class="sig-param">
            <span class="n">
             gpu_id
            </span>
           </em>
           <span class="sig-paren">
            )
           </span>
           <a class="headerlink" href="#trtorch.set_device" title="Permalink to this definition">
            ¶
           </a>
          </dt>
          <dd>
          </dd>
         </dl>
         <dl class="py function">
          <dt id="trtorch.compile">
           <code class="sig-prename descclassname">
            trtorch.
           </code>
           <code class="sig-name descname">
            compile
           </code>
           <span class="sig-paren">
            (
           </span>
           <em class="sig-param">
            module: torch.jit._script.ScriptModule
           </em>
           ,
           <em class="sig-param">
            inputs=[]
           </em>
           ,
           <em class="sig-param">
            device=None
           </em>
           ,
           <em class="sig-param">
            disable_tf32=False
           </em>
           ,
           <em class="sig-param">
            sparse_weights=False
           </em>
           ,
           <em class="sig-param">
            enabled_precisions={}
           </em>
           ,
           <em class="sig-param">
            refit=False
           </em>
           ,
           <em class="sig-param">
            debug=False
           </em>
           ,
           <em class="sig-param">
            strict_types=False
           </em>
           ,
           <em class="sig-param">
            capability=&lt;EngineCapability.default: 0&gt;
           </em>
           ,
           <em class="sig-param">
            num_min_timing_iters=2
           </em>
           ,
           <em class="sig-param">
            num_avg_timing_iters=1
           </em>
           ,
           <em class="sig-param">
            workspace_size=0
           </em>
           ,
           <em class="sig-param">
            max_batch_size=0
           </em>
           ,
           <em class="sig-param">
            calibrator=None
           </em>
           ,
           <em class="sig-param">
            truncate_long_and_double=False
           </em>
           ,
           <em class="sig-param">
            require_full_compilation=False
           </em>
           ,
           <em class="sig-param">
            min_block_size=3
           </em>
           ,
           <em class="sig-param">
            torch_executed_ops=[]
           </em>
           ,
           <em class="sig-param">
            torch_executed_modules=[]
           </em>
           <span class="sig-paren">
            )
           </span>
           → torch.jit._script.ScriptModule
           <a class="headerlink" href="#trtorch.compile" title="Permalink to this definition">
            ¶
           </a>
          </dt>
          <dd>
           <p>
            Compile a TorchScript module for NVIDIA GPUs using TensorRT
           </p>
           <p>
            Takes a existing TorchScript module and a set of settings to configure the compiler
and will convert methods to JIT Graphs which call equivalent TensorRT engines
           </p>
           <p>
            Converts specifically the forward method of a TorchScript Module
           </p>
           <dl class="field-list simple">
            <dt class="field-odd">
             Parameters
            </dt>
            <dd class="field-odd">
             <p>
              <strong>
               module
              </strong>
              (
              <em>
               torch.jit.ScriptModule
              </em>
              ) – Source module, a result of tracing or scripting a PyTorch
              <code class="docutils literal notranslate">
               <span class="pre">
                torch.nn.Module
               </span>
              </code>
             </p>
            </dd>
            <dt class="field-even">
             Keyword Arguments
            </dt>
            <dd class="field-even">
             <ul class="simple">
              <li>
               <p>
                <strong>
                 inputs
                </strong>
                (
                <em>
                 List
                </em>
                <em>
                 [
                </em>
                <em>
                 Union
                </em>
                <em>
                 (
                </em>
                <a class="reference internal" href="#trtorch.Input" title="trtorch.Input">
                 <em>
                  trtorch.Input
                 </em>
                </a>
                <em>
                 ,
                </em>
                <em>
                 torch.Tensor
                </em>
                <em>
                 )
                </em>
                <em>
                 ]
                </em>
                ) –
               </p>
               <p>
                <strong>
                 Required
                </strong>
                List of specifications of input shape, dtype and memory layout for inputs to the module. This argument is required. Input Sizes can be specified as torch sizes, tuples or lists. dtypes can be specified using
torch datatypes or trtorch datatypes and you can use either torch devices or the trtorch device type enum
to select device type.
               </p>
               <div class="highlight-cpp notranslate">
                <div class="highlight">
                 <pre><span></span>input=[
    trtorch.Input((1, 3, 224, 224)), # Static NCHW input shape for input #1
    trtorch.Input(
        min_shape=(1, 224, 224, 3),
        opt_shape=(1, 512, 512, 3),
        max_shape=(1, 1024, 1024, 3),
        dtype=torch.int32
        format=torch.channel_last
    ), # Dynamic input shape for input #2
    torch.randn((1, 3, 224, 244)) # Use an example tensor and let trtorch infer settings
]
</pre>
                </div>
               </div>
              </li>
              <li>
               <p>
                <strong>
                 device
                </strong>
                (
                <em>
                 Union
                </em>
                <em>
                 (
                </em>
                <a class="reference internal" href="#trtorch.Device" title="trtorch.Device">
                 <em>
                  trtorch.Device
                 </em>
                </a>
                <em>
                 ,
                </em>
                <em>
                 torch.device
                </em>
                <em>
                 ,
                </em>
                <em>
                 dict
                </em>
                <em>
                 )
                </em>
                ) –
               </p>
               <p>
                Target device for TensorRT engines to run on
               </p>
               <div class="highlight-cpp notranslate">
                <div class="highlight">
                 <pre><span></span><span class="n">device</span><span class="o">=</span><span class="n">trtorch</span><span class="p">.</span><span class="n">Device</span><span class="p">(</span><span class="s">"dla:1"</span><span class="p">,</span><span class="w"> </span><span class="n">allow_gpu_fallback</span><span class="o">=</span><span class="n">True</span><span class="p">)</span><span class="w"></span>
</pre>
                </div>
               </div>
              </li>
              <li>
               <p>
                <strong>
                 disable_tf32
                </strong>
                (
                <em>
                 bool
                </em>
                ) – Force FP32 layers to use traditional as FP32 format vs the default behavior of rounding the inputs to 10-bit mantissas before multiplying, but accumulates the sum using 23-bit mantissas
               </p>
              </li>
              <li>
               <p>
                <strong>
                 sparse_weights
                </strong>
                (
                <em>
                 bool
                </em>
                ) – Enable sparsity for convolution and fully connected layers.
               </p>
              </li>
              <li>
               <p>
                <strong>
                 enabled_precision
                </strong>
                (
                <em>
                 Set
                </em>
                <em>
                 (
                </em>
                <em>
                 Union
                </em>
                <em>
                 (
                </em>
                <em>
                 torch.dtype
                </em>
                <em>
                 ,
                </em>
                <a class="reference internal" href="#trtorch.dtype" title="trtorch.dtype">
                 <em>
                  trtorch.dtype
                 </em>
                </a>
                <em>
                 )
                </em>
                <em>
                 )
                </em>
                ) – The set of datatypes that TensorRT can use when selecting kernels
               </p>
              </li>
              <li>
               <p>
                <strong>
                 refit
                </strong>
                (
                <em>
                 bool
                </em>
                ) – Enable refitting
               </p>
              </li>
              <li>
               <p>
                <strong>
                 debug
                </strong>
                (
                <em>
                 bool
                </em>
                ) – Enable debuggable engine
               </p>
              </li>
              <li>
               <p>
                <strong>
                 strict_types
                </strong>
                (
                <em>
                 bool
                </em>
                ) – Kernels should strictly run in a particular operating precision. Enabled precision should only have one type in the set
               </p>
              </li>
              <li>
               <p>
                <strong>
                 capability
                </strong>
                (
                <a class="reference internal" href="#trtorch.EngineCapability" title="trtorch.EngineCapability">
                 <em>
                  trtorch.EngineCapability
                 </em>
                </a>
                ) – Restrict kernel selection to safe gpu kernels or safe dla kernels
               </p>
              </li>
              <li>
               <p>
                <strong>
                 num_min_timing_iters
                </strong>
                (
                <em>
                 int
                </em>
                ) – Number of minimization timing iterations used to select kernels
               </p>
              </li>
              <li>
               <p>
                <strong>
                 num_avg_timing_iters
                </strong>
                (
                <em>
                 int
                </em>
                ) – Number of averaging timing iterations used to select kernels
               </p>
              </li>
              <li>
               <p>
                <strong>
                 workspace_size
                </strong>
                (
                <em>
                 int
                </em>
                ) – Maximum size of workspace given to TensorRT
               </p>
              </li>
              <li>
               <p>
                <strong>
                 max_batch_size
                </strong>
                (
                <em>
                 int
                </em>
                ) – Maximum batch size (must be &gt;= 1 to be set, 0 means not set)
               </p>
              </li>
              <li>
               <p>
                <strong>
                 truncate_long_and_double
                </strong>
                (
                <em>
                 bool
                </em>
                ) – Truncate weights provided in int64 or double (float64) to int32 and float32
               </p>
              </li>
              <li>
               <p>
                <strong>
                 calibrator
                </strong>
                (
                <em>
                 Union
                </em>
                <em>
                 (
                </em>
                <em>
                 trtorch._C.IInt8Calibrator
                </em>
                <em>
                 ,
                </em>
                <em>
                 tensorrt.IInt8Calibrator
                </em>
                <em>
                 )
                </em>
                ) – Calibrator object which will provide data to the PTQ system for INT8 Calibration
               </p>
              </li>
              <li>
               <p>
                <strong>
                 require_full_compilation
                </strong>
                (
                <em>
                 bool
                </em>
                ) – Require modules to be compiled end to end or return an error as opposed to returning a hybrid graph where operations that cannot be run in TensorRT are run in PyTorch
               </p>
              </li>
              <li>
               <p>
                <strong>
                 min_block_size
                </strong>
                (
                <em>
                 int
                </em>
                ) – The minimum number of contiguous TensorRT convertable operations in order to run a set of operations in TensorRT
               </p>
              </li>
              <li>
               <p>
                <strong>
                 torch_executed_ops
                </strong>
                (
                <em>
                 List
                </em>
                <em>
                 [
                </em>
                <em>
                 str
                </em>
                <em>
                 ]
                </em>
                ) – List of aten operators that must be run in PyTorch. An error will be thrown if this list is not empty but
                <code class="docutils literal notranslate">
                 <span class="pre">
                  require_full_compilation
                 </span>
                </code>
                is True
               </p>
              </li>
              <li>
               <p>
                <strong>
                 torch_executed_modules
                </strong>
                (
                <em>
                 List
                </em>
                <em>
                 [
                </em>
                <em>
                 str
                </em>
                <em>
                 ]
                </em>
                ) – List of modules that must be run in PyTorch. An error will be thrown if this list is not empty but
                <code class="docutils literal notranslate">
                 <span class="pre">
                  require_full_compilation
                 </span>
                </code>
                is True
               </p>
              </li>
             </ul>
            </dd>
            <dt class="field-odd">
             Returns
            </dt>
            <dd class="field-odd">
             <p>
              Compiled TorchScript Module, when run it will execute via TensorRT
             </p>
            </dd>
            <dt class="field-even">
             Return type
            </dt>
            <dd class="field-even">
             <p>
              torch.jit.ScriptModule
             </p>
            </dd>
           </dl>
          </dd>
         </dl>
         <dl class="py function">
          <dt id="trtorch.convert_method_to_trt_engine">
           <code class="sig-prename descclassname">
            trtorch.
           </code>
           <code class="sig-name descname">
            convert_method_to_trt_engine
           </code>
           <span class="sig-paren">
            (
           </span>
           <em class="sig-param">
            module: torch.jit._script.ScriptModule
           </em>
           ,
           <em class="sig-param">
            method_name: str
           </em>
           ,
           <em class="sig-param">
            inputs=[]
           </em>
           ,
           <em class="sig-param">
            device=None
           </em>
           ,
           <em class="sig-param">
            disable_tf32=False
           </em>
           ,
           <em class="sig-param">
            sparse_weights=False
           </em>
           ,
           <em class="sig-param">
            enabled_precisions={}
           </em>
           ,
           <em class="sig-param">
            refit=False
           </em>
           ,
           <em class="sig-param">
            debug=False
           </em>
           ,
           <em class="sig-param">
            strict_types=False
           </em>
           ,
           <em class="sig-param">
            capability=&lt;EngineCapability.default: 0&gt;
           </em>
           ,
           <em class="sig-param">
            num_min_timing_iters=2
           </em>
           ,
           <em class="sig-param">
            num_avg_timing_iters=1
           </em>
           ,
           <em class="sig-param">
            workspace_size=0
           </em>
           ,
           <em class="sig-param">
            max_batch_size=0
           </em>
           ,
           <em class="sig-param">
            truncate_long_and_double=False
           </em>
           ,
           <em class="sig-param">
            calibrator=None
           </em>
           <span class="sig-paren">
            )
           </span>
           → str
           <a class="headerlink" href="#trtorch.convert_method_to_trt_engine" title="Permalink to this definition">
            ¶
           </a>
          </dt>
          <dd>
           <p>
            Convert a TorchScript module method to a serialized TensorRT engine
           </p>
           <p>
            Converts a specified method of a module to a serialized TensorRT engine given a dictionary of conversion settings
           </p>
           <dl class="field-list simple">
            <dt class="field-odd">
             Parameters
            </dt>
            <dd class="field-odd">
             <ul class="simple">
              <li>
               <p>
                <strong>
                 module
                </strong>
                (
                <em>
                 torch.jit.ScriptModule
                </em>
                ) – Source module, a result of tracing or scripting a PyTorch
                <code class="docutils literal notranslate">
                 <span class="pre">
                  torch.nn.Module
                 </span>
                </code>
               </p>
              </li>
              <li>
               <p>
                <strong>
                 method_name
                </strong>
                (
                <em>
                 str
                </em>
                ) – Name of method to convert
               </p>
              </li>
             </ul>
            </dd>
            <dt class="field-even">
             Keyword Arguments
            </dt>
            <dd class="field-even">
             <ul class="simple">
              <li>
               <p>
                <strong>
                 inputs
                </strong>
                (
                <em>
                 List
                </em>
                <em>
                 [
                </em>
                <em>
                 Union
                </em>
                <em>
                 (
                </em>
                <a class="reference internal" href="#trtorch.Input" title="trtorch.Input">
                 <em>
                  trtorch.Input
                 </em>
                </a>
                <em>
                 ,
                </em>
                <em>
                 torch.Tensor
                </em>
                <em>
                 )
                </em>
                <em>
                 ]
                </em>
                ) –
               </p>
               <p>
                <strong>
                 Required
                </strong>
                List of specifications of input shape, dtype and memory layout for inputs to the module. This argument is required. Input Sizes can be specified as torch sizes, tuples or lists. dtypes can be specified using
torch datatypes or trtorch datatypes and you can use either torch devices or the trtorch device type enum
to select device type.
               </p>
               <div class="highlight-cpp notranslate">
                <div class="highlight">
                 <pre><span></span>input=[
    trtorch.Input((1, 3, 224, 224)), # Static NCHW input shape for input #1
    trtorch.Input(
        min_shape=(1, 224, 224, 3),
        opt_shape=(1, 512, 512, 3),
        max_shape=(1, 1024, 1024, 3),
        dtype=torch.int32
        format=torch.channel_last
    ), # Dynamic input shape for input #2
    torch.randn((1, 3, 224, 244)) # Use an example tensor and let trtorch infer settings
]
</pre>
                </div>
               </div>
              </li>
              <li>
               <p>
                <strong>
                 device
                </strong>
                (
                <em>
                 Union
                </em>
                <em>
                 (
                </em>
                <a class="reference internal" href="#trtorch.Device" title="trtorch.Device">
                 <em>
                  trtorch.Device
                 </em>
                </a>
                <em>
                 ,
                </em>
                <em>
                 torch.device
                </em>
                <em>
                 ,
                </em>
                <em>
                 dict
                </em>
                <em>
                 )
                </em>
                ) –
               </p>
               <p>
                Target device for TensorRT engines to run on
               </p>
               <div class="highlight-cpp notranslate">
                <div class="highlight">
                 <pre><span></span><span class="n">device</span><span class="o">=</span><span class="n">trtorch</span><span class="p">.</span><span class="n">Device</span><span class="p">(</span><span class="s">"dla:1"</span><span class="p">,</span><span class="w"> </span><span class="n">allow_gpu_fallback</span><span class="o">=</span><span class="n">True</span><span class="p">)</span><span class="w"></span>
</pre>
                </div>
               </div>
              </li>
              <li>
               <p>
                <strong>
                 disable_tf32
                </strong>
                (
                <em>
                 bool
                </em>
                ) – Force FP32 layers to use traditional as FP32 format vs the default behavior of rounding the inputs to 10-bit mantissas before multiplying, but accumulates the sum using 23-bit mantissas
               </p>
              </li>
              <li>
               <p>
                <strong>
                 sparse_weights
                </strong>
                (
                <em>
                 bool
                </em>
                ) – Enable sparsity for convolution and fully connected layers.
               </p>
              </li>
              <li>
               <p>
                <strong>
                 enabled_precision
                </strong>
                (
                <em>
                 Set
                </em>
                <em>
                 (
                </em>
                <em>
                 Union
                </em>
                <em>
                 (
                </em>
                <em>
                 torch.dtype
                </em>
                <em>
                 ,
                </em>
                <a class="reference internal" href="#trtorch.dtype" title="trtorch.dtype">
                 <em>
                  trtorch.dtype
                 </em>
                </a>
                <em>
                 )
                </em>
                <em>
                 )
                </em>
                ) – The set of datatypes that TensorRT can use when selecting kernels
               </p>
              </li>
              <li>
               <p>
                <strong>
                 refit
                </strong>
                (
                <em>
                 bool
                </em>
                ) – Enable refitting
               </p>
              </li>
              <li>
               <p>
                <strong>
                 debug
                </strong>
                (
                <em>
                 bool
                </em>
                ) – Enable debuggable engine
               </p>
              </li>
              <li>
               <p>
                <strong>
                 strict_types
                </strong>
                (
                <em>
                 bool
                </em>
                ) – Kernels should strictly run in a particular operating precision. Enabled precision should only have one type in the set
               </p>
              </li>
              <li>
               <p>
                <strong>
                 capability
                </strong>
                (
                <a class="reference internal" href="#trtorch.EngineCapability" title="trtorch.EngineCapability">
                 <em>
                  trtorch.EngineCapability
                 </em>
                </a>
                ) – Restrict kernel selection to safe gpu kernels or safe dla kernels
               </p>
              </li>
              <li>
               <p>
                <strong>
                 num_min_timing_iters
                </strong>
                (
                <em>
                 int
                </em>
                ) – Number of minimization timing iterations used to select kernels
               </p>
              </li>
              <li>
               <p>
                <strong>
                 num_avg_timing_iters
                </strong>
                (
                <em>
                 int
                </em>
                ) – Number of averaging timing iterations used to select kernels
               </p>
              </li>
              <li>
               <p>
                <strong>
                 workspace_size
                </strong>
                (
                <em>
                 int
                </em>
                ) – Maximum size of workspace given to TensorRT
               </p>
              </li>
              <li>
               <p>
                <strong>
                 max_batch_size
                </strong>
                (
                <em>
                 int
                </em>
                ) – Maximum batch size (must be &gt;= 1 to be set, 0 means not set)
               </p>
              </li>
              <li>
               <p>
                <strong>
                 truncate_long_and_double
                </strong>
                (
                <em>
                 bool
                </em>
                ) – Truncate weights provided in int64 or double (float64) to int32 and float32
               </p>
              </li>
              <li>
               <p>
                <strong>
                 calibrator
                </strong>
                (
                <em>
                 Union
                </em>
                <em>
                 (
                </em>
                <em>
                 trtorch._C.IInt8Calibrator
                </em>
                <em>
                 ,
                </em>
                <em>
                 tensorrt.IInt8Calibrator
                </em>
                <em>
                 )
                </em>
                ) – Calibrator object which will provide data to the PTQ system for INT8 Calibration
               </p>
              </li>
             </ul>
            </dd>
            <dt class="field-odd">
             Returns
            </dt>
            <dd class="field-odd">
             <p>
              Serialized TensorRT engine, can either be saved to a file or deserialized via TensorRT APIs
             </p>
            </dd>
            <dt class="field-even">
             Return type
            </dt>
            <dd class="field-even">
             <p>
              bytes
             </p>
            </dd>
           </dl>
          </dd>
         </dl>
         <dl class="py function">
          <dt id="trtorch.check_method_op_support">
           <code class="sig-prename descclassname">
            trtorch.
           </code>
           <code class="sig-name descname">
            check_method_op_support
           </code>
           <span class="sig-paren">
            (
           </span>
           <em class="sig-param">
            <span class="n">
             module
            </span>
            <span class="p">
             :
            </span>
            <span class="n">
             torch.jit._script.ScriptModule
            </span>
           </em>
           ,
           <em class="sig-param">
            <span class="n">
             method_name
            </span>
            <span class="p">
             :
            </span>
            <span class="n">
             str
            </span>
           </em>
           <span class="sig-paren">
            )
           </span>
           → bool
           <a class="headerlink" href="#trtorch.check_method_op_support" title="Permalink to this definition">
            ¶
           </a>
          </dt>
          <dd>
           <p>
            Checks to see if a method is fully supported by TRTorch
           </p>
           <p>
            Checks if a method of a TorchScript module can be compiled by TRTorch, if not, a list of operators
that are not supported are printed out and the function returns false, else true.
           </p>
           <dl class="field-list simple">
            <dt class="field-odd">
             Parameters
            </dt>
            <dd class="field-odd">
             <ul class="simple">
              <li>
               <p>
                <strong>
                 module
                </strong>
                (
                <em>
                 torch.jit.ScriptModule
                </em>
                ) – Source module, a result of tracing or scripting a PyTorch
                <code class="docutils literal notranslate">
                 <span class="pre">
                  torch.nn.Module
                 </span>
                </code>
               </p>
              </li>
              <li>
               <p>
                <strong>
                 method_name
                </strong>
                (
                <em>
                 str
                </em>
                ) – Name of method to check
               </p>
              </li>
             </ul>
            </dd>
            <dt class="field-even">
             Returns
            </dt>
            <dd class="field-even">
             <p>
              True if supported Method
             </p>
            </dd>
            <dt class="field-odd">
             Return type
            </dt>
            <dd class="field-odd">
             <p>
              bool
             </p>
            </dd>
           </dl>
          </dd>
         </dl>
         <dl class="py function">
          <dt id="trtorch.embed_engine_in_new_module">
           <code class="sig-prename descclassname">
            trtorch.
           </code>
           <code class="sig-name descname">
            embed_engine_in_new_module
           </code>
           <span class="sig-paren">
            (
           </span>
           <em class="sig-param">
            <span class="n">
             serialized_engine
            </span>
            <span class="p">
             :
            </span>
            <span class="n">
             bytes
            </span>
           </em>
           ,
           <em class="sig-param">
            <span class="n">
             device
            </span>
            <span class="o">
             =
            </span>
            <span class="default_value">
             None
            </span>
           </em>
           <span class="sig-paren">
            )
           </span>
           → torch.jit._script.ScriptModule
           <a class="headerlink" href="#trtorch.embed_engine_in_new_module" title="Permalink to this definition">
            ¶
           </a>
          </dt>
          <dd>
           <p>
            Takes a pre-built serialized TensorRT engine and embeds it within a TorchScript module
           </p>
           <p>
            Takes a pre-built serialied TensorRT engine (as bytes) and embeds it within a TorchScript module.
Registers the forward method to execute the TensorRT engine with the function signature:
           </p>
           <blockquote>
            <div>
             <p>
              forward(Tensor[]) -&gt; Tensor[]
             </p>
            </div>
           </blockquote>
           <p>
            Module can be save with engine embedded with torch.jit.save and moved / loaded according to TRTorch portability rules
           </p>
           <dl class="field-list simple">
            <dt class="field-odd">
             Parameters
            </dt>
            <dd class="field-odd">
             <p>
              <strong>
               serialized_engine
              </strong>
              (
              <em>
               bytes
              </em>
              ) – Serialized TensorRT engine from either TRTorch or TensorRT APIs
             </p>
            </dd>
            <dt class="field-even">
             Keyword Arguments
            </dt>
            <dd class="field-even">
             <p>
              <strong>
               device
              </strong>
              (
              <em>
               Union
              </em>
              <em>
               (
              </em>
              <a class="reference internal" href="#trtorch.Device" title="trtorch.Device">
               <em>
                trtorch.Device
               </em>
              </a>
              <em>
               ,
              </em>
              <em>
               torch.device
              </em>
              <em>
               ,
              </em>
              <em>
               dict
              </em>
              <em>
               )
              </em>
              ) – Target device to run engine on. Must be compatible with engine provided. Default: Current active device
             </p>
            </dd>
            <dt class="field-odd">
             Returns
            </dt>
            <dd class="field-odd">
             <p>
              New TorchScript module with engine embedded
             </p>
            </dd>
            <dt class="field-even">
             Return type
            </dt>
            <dd class="field-even">
             <p>
              torch.jit.ScriptModule
             </p>
            </dd>
           </dl>
          </dd>
         </dl>
         <dl class="py function">
          <dt id="trtorch.get_build_info">
           <code class="sig-prename descclassname">
            trtorch.
           </code>
           <code class="sig-name descname">
            get_build_info
           </code>
           <span class="sig-paren">
            (
           </span>
           <span class="sig-paren">
            )
           </span>
           → str
           <a class="headerlink" href="#trtorch.get_build_info" title="Permalink to this definition">
            ¶
           </a>
          </dt>
          <dd>
           <p>
            Returns a string containing the build information of TRTorch distribution
           </p>
           <dl class="field-list simple">
            <dt class="field-odd">
             Returns
            </dt>
            <dd class="field-odd">
             <p>
              String containing the build information for TRTorch distribution
             </p>
            </dd>
            <dt class="field-even">
             Return type
            </dt>
            <dd class="field-even">
             <p>
              str
             </p>
            </dd>
           </dl>
          </dd>
         </dl>
         <dl class="py function">
          <dt id="trtorch.dump_build_info">
           <code class="sig-prename descclassname">
            trtorch.
           </code>
           <code class="sig-name descname">
            dump_build_info
           </code>
           <span class="sig-paren">
            (
           </span>
           <span class="sig-paren">
            )
           </span>
           <a class="headerlink" href="#trtorch.dump_build_info" title="Permalink to this definition">
            ¶
           </a>
          </dt>
          <dd>
           <p>
            Prints build information about the TRTorch distribution to stdout
           </p>
          </dd>
         </dl>
         <dl class="py function">
          <dt id="trtorch.TensorRTCompileSpec">
           <code class="sig-prename descclassname">
            trtorch.
           </code>
           <code class="sig-name descname">
            TensorRTCompileSpec
           </code>
           <span class="sig-paren">
            (
           </span>
           <em class="sig-param">
            inputs=[]
           </em>
           ,
           <em class="sig-param">
            device=None
           </em>
           ,
           <em class="sig-param">
            disable_tf32=False
           </em>
           ,
           <em class="sig-param">
            sparse_weights=False
           </em>
           ,
           <em class="sig-param">
            enabled_precisions={}
           </em>
           ,
           <em class="sig-param">
            refit=False
           </em>
           ,
           <em class="sig-param">
            debug=False
           </em>
           ,
           <em class="sig-param">
            strict_types=False
           </em>
           ,
           <em class="sig-param">
            capability=&lt;EngineCapability.default: 0&gt;
           </em>
           ,
           <em class="sig-param">
            num_min_timing_iters=2
           </em>
           ,
           <em class="sig-param">
            num_avg_timing_iters=1
           </em>
           ,
           <em class="sig-param">
            workspace_size=0
           </em>
           ,
           <em class="sig-param">
            max_batch_size=0
           </em>
           ,
           <em class="sig-param">
            truncate_long_and_double=False
           </em>
           ,
           <em class="sig-param">
            calibrator=None
           </em>
           <span class="sig-paren">
            )
           </span>
           → &lt;torch._C.ScriptClass object at 0x7f37d82123b0&gt;
           <a class="headerlink" href="#trtorch.TensorRTCompileSpec" title="Permalink to this definition">
            ¶
           </a>
          </dt>
          <dd>
           <p>
            Utility to create a formated spec dictionary for using the PyTorch TensorRT backend
           </p>
           <dl class="field-list simple">
            <dt class="field-odd">
             Keyword Arguments
            </dt>
            <dd class="field-odd">
             <ul class="simple">
              <li>
               <p>
                <strong>
                 inputs
                </strong>
                (
                <em>
                 List
                </em>
                <em>
                 [
                </em>
                <em>
                 Union
                </em>
                <em>
                 (
                </em>
                <a class="reference internal" href="#trtorch.Input" title="trtorch.Input">
                 <em>
                  trtorch.Input
                 </em>
                </a>
                <em>
                 ,
                </em>
                <em>
                 torch.Tensor
                </em>
                <em>
                 )
                </em>
                <em>
                 ]
                </em>
                ) –
               </p>
               <p>
                <strong>
                 Required
                </strong>
                List of specifications of input shape, dtype and memory layout for inputs to the module. This argument is required. Input Sizes can be specified as torch sizes, tuples or lists. dtypes can be specified using
torch datatypes or trtorch datatypes and you can use either torch devices or the trtorch device type enum
to select device type.
               </p>
               <div class="highlight-cpp notranslate">
                <div class="highlight">
                 <pre><span></span>input=[
    trtorch.Input((1, 3, 224, 224)), # Static NCHW input shape for input #1
    trtorch.Input(
        min_shape=(1, 224, 224, 3),
        opt_shape=(1, 512, 512, 3),
        max_shape=(1, 1024, 1024, 3),
        dtype=torch.int32
        format=torch.channel_last
    ), # Dynamic input shape for input #2
    torch.randn((1, 3, 224, 244)) # Use an example tensor and let trtorch infer settings
]
</pre>
                </div>
               </div>
              </li>
              <li>
               <p>
                <strong>
                 device
                </strong>
                (
                <em>
                 Union
                </em>
                <em>
                 (
                </em>
                <a class="reference internal" href="#trtorch.Device" title="trtorch.Device">
                 <em>
                  trtorch.Device
                 </em>
                </a>
                <em>
                 ,
                </em>
                <em>
                 torch.device
                </em>
                <em>
                 ,
                </em>
                <em>
                 dict
                </em>
                <em>
                 )
                </em>
                ) –
               </p>
               <p>
                Target device for TensorRT engines to run on
               </p>
               <div class="highlight-cpp notranslate">
                <div class="highlight">
                 <pre><span></span><span class="n">device</span><span class="o">=</span><span class="n">trtorch</span><span class="p">.</span><span class="n">Device</span><span class="p">(</span><span class="s">"dla:1"</span><span class="p">,</span><span class="w"> </span><span class="n">allow_gpu_fallback</span><span class="o">=</span><span class="n">True</span><span class="p">)</span><span class="w"></span>
</pre>
                </div>
               </div>
              </li>
              <li>
               <p>
                <strong>
                 disable_tf32
                </strong>
                (
                <em>
                 bool
                </em>
                ) – Force FP32 layers to use traditional as FP32 format vs the default behavior of rounding the inputs to 10-bit mantissas before multiplying, but accumulates the sum using 23-bit mantissas
               </p>
              </li>
              <li>
               <p>
                <strong>
                 sparse_weights
                </strong>
                (
                <em>
                 bool
                </em>
                ) – Enable sparsity for convolution and fully connected layers.
               </p>
              </li>
              <li>
               <p>
                <strong>
                 enabled_precision
                </strong>
                (
                <em>
                 Set
                </em>
                <em>
                 (
                </em>
                <em>
                 Union
                </em>
                <em>
                 (
                </em>
                <em>
                 torch.dtype
                </em>
                <em>
                 ,
                </em>
                <a class="reference internal" href="#trtorch.dtype" title="trtorch.dtype">
                 <em>
                  trtorch.dtype
                 </em>
                </a>
                <em>
                 )
                </em>
                <em>
                 )
                </em>
                ) – The set of datatypes that TensorRT can use when selecting kernels
               </p>
              </li>
              <li>
               <p>
                <strong>
                 refit
                </strong>
                (
                <em>
                 bool
                </em>
                ) – Enable refitting
               </p>
              </li>
              <li>
               <p>
                <strong>
                 debug
                </strong>
                (
                <em>
                 bool
                </em>
                ) – Enable debuggable engine
               </p>
              </li>
              <li>
               <p>
                <strong>
                 strict_types
                </strong>
                (
                <em>
                 bool
                </em>
                ) – Kernels should strictly run in a particular operating precision. Enabled precision should only have one type in the set
               </p>
              </li>
              <li>
               <p>
                <strong>
                 capability
                </strong>
                (
                <a class="reference internal" href="#trtorch.EngineCapability" title="trtorch.EngineCapability">
                 <em>
                  trtorch.EngineCapability
                 </em>
                </a>
                ) – Restrict kernel selection to safe gpu kernels or safe dla kernels
               </p>
              </li>
              <li>
               <p>
                <strong>
                 num_min_timing_iters
                </strong>
                (
                <em>
                 int
                </em>
                ) – Number of minimization timing iterations used to select kernels
               </p>
              </li>
              <li>
               <p>
                <strong>
                 num_avg_timing_iters
                </strong>
                (
                <em>
                 int
                </em>
                ) – Number of averaging timing iterations used to select kernels
               </p>
              </li>
              <li>
               <p>
                <strong>
                 workspace_size
                </strong>
                (
                <em>
                 int
                </em>
                ) – Maximum size of workspace given to TensorRT
               </p>
              </li>
              <li>
               <p>
                <strong>
                 max_batch_size
                </strong>
                (
                <em>
                 int
                </em>
                ) – Maximum batch size (must be &gt;= 1 to be set, 0 means not set)
               </p>
              </li>
              <li>
               <p>
                <strong>
                 truncate_long_and_double
                </strong>
                (
                <em>
                 bool
                </em>
                ) – Truncate weights provided in int64 or double (float64) to int32 and float32
               </p>
              </li>
              <li>
               <p>
                <strong>
                 calibrator
                </strong>
                – Calibrator object which will provide data to the PTQ system for INT8 Calibration
               </p>
              </li>
             </ul>
            </dd>
           </dl>
          </dd>
         </dl>
        </section>
        <section id="classes">
         <h2 id="classes">
          Classes
          <a class="headerlink" href="#classes" title="Permalink to this headline">
           ¶
          </a>
         </h2>
         <dl class="py class">
          <dt id="trtorch.Input">
           <em class="property">
            class
           </em>
           <code class="sig-prename descclassname">
            trtorch.
           </code>
           <code class="sig-name descname">
            Input
           </code>
           <span class="sig-paren">
            (
           </span>
           <em class="sig-param">
            <span class="o">
             *
            </span>
            <span class="n">
             args
            </span>
           </em>
           ,
           <em class="sig-param">
            <span class="o">
             **
            </span>
            <span class="n">
             kwargs
            </span>
           </em>
           <span class="sig-paren">
            )
           </span>
           <a class="headerlink" href="#trtorch.Input" title="Permalink to this definition">
            ¶
           </a>
          </dt>
          <dd>
           <p>
            Defines an input to a module in terms of expected shape, data type and tensor format.
           </p>
           <dl class="py method">
            <dt id="trtorch.Input.__init__">
             <code class="sig-name descname">
              __init__
             </code>
             <span class="sig-paren">
              (
             </span>
             <em class="sig-param">
              <span class="o">
               *
              </span>
              <span class="n">
               args
              </span>
             </em>
             ,
             <em class="sig-param">
              <span class="o">
               **
              </span>
              <span class="n">
               kwargs
              </span>
             </em>
             <span class="sig-paren">
              )
             </span>
             <a class="headerlink" href="#trtorch.Input.__init__" title="Permalink to this definition">
              ¶
             </a>
            </dt>
            <dd>
             <p>
              __init__ Method for trtorch.Input
             </p>
             <p>
              Input accepts one of a few construction patterns
             </p>
             <dl class="field-list simple">
              <dt class="field-odd">
               Parameters
              </dt>
              <dd class="field-odd">
               <p>
                <strong>
                 shape
                </strong>
                (
                <em>
                 Tuple
                </em>
                <em>
                 or
                </em>
                <em>
                 List
                </em>
                <em>
                 ,
                </em>
                <em>
                 optional
                </em>
                ) – Static shape of input tensor
               </p>
              </dd>
              <dt class="field-even">
               Keyword Arguments
              </dt>
              <dd class="field-even">
               <ul class="simple">
                <li>
                 <p>
                  <strong>
                   shape
                  </strong>
                  (
                  <em>
                   Tuple
                  </em>
                  <em>
                   or
                  </em>
                  <em>
                   List
                  </em>
                  <em>
                   ,
                  </em>
                  <em>
                   optional
                  </em>
                  ) – Static shape of input tensor
                 </p>
                </li>
                <li>
                 <p>
                  <strong>
                   min_shape
                  </strong>
                  (
                  <em>
                   Tuple
                  </em>
                  <em>
                   or
                  </em>
                  <em>
                   List
                  </em>
                  <em>
                   ,
                  </em>
                  <em>
                   optional
                  </em>
                  ) – Min size of input tensor’s shape range
Note: All three of min_shape, opt_shape, max_shape must be provided, there must be no positional arguments, shape must not be defined and implictly this sets Input’s shape_mode to DYNAMIC
                 </p>
                </li>
                <li>
                 <p>
                  <strong>
                   opt_shape
                  </strong>
                  (
                  <em>
                   Tuple
                  </em>
                  <em>
                   or
                  </em>
                  <em>
                   List
                  </em>
                  <em>
                   ,
                  </em>
                  <em>
                   optional
                  </em>
                  ) – Opt size of input tensor’s shape range
Note: All three of min_shape, opt_shape, max_shape must be provided, there must be no positional arguments, shape must not be defined and implictly this sets Input’s shape_mode to DYNAMIC
                 </p>
                </li>
                <li>
                 <p>
                  <strong>
                   max_shape
                  </strong>
                  (
                  <em>
                   Tuple
                  </em>
                  <em>
                   or
                  </em>
                  <em>
                   List
                  </em>
                  <em>
                   ,
                  </em>
                  <em>
                   optional
                  </em>
                  ) – Max size of input tensor’s shape range
Note: All three of min_shape, opt_shape, max_shape must be provided, there must be no positional arguments, shape must not be defined and implictly this sets Input’s shape_mode to DYNAMIC
                 </p>
                </li>
                <li>
                 <p>
                  <strong>
                   dtype
                  </strong>
                  (
                  <em>
                   torch.dtype
                  </em>
                  <em>
                   or
                  </em>
                  <a class="reference internal" href="#trtorch.dtype" title="trtorch.dtype">
                   <em>
                    trtorch.dtype
                   </em>
                  </a>
                  ) – Expected data type for input tensor (default: trtorch.dtype.float32)
                 </p>
                </li>
                <li>
                 <p>
                  <strong>
                   format
                  </strong>
                  (
                  <em>
                   torch.memory_format
                  </em>
                  <em>
                   or
                  </em>
                  <a class="reference internal" href="#trtorch.TensorFormat" title="trtorch.TensorFormat">
                   <em>
                    trtorch.TensorFormat
                   </em>
                  </a>
                  ) – The expected format of the input tensor (default: trtorch.TensorFormat.NCHW)
                 </p>
                </li>
               </ul>
              </dd>
             </dl>
             <p class="rubric">
              Examples
             </p>
             <ul class="simple">
              <li>
               <p>
                Input([1,3,32,32], dtype=torch.float32, format=torch.channel_last)
               </p>
              </li>
              <li>
               <p>
                Input(shape=(1,3,32,32), dtype=trtorch.dtype.int32, format=trtorch.TensorFormat.NCHW)
               </p>
              </li>
              <li>
               <p>
                Input(min_shape=(1,3,32,32), opt_shape=[2,3,32,32], max_shape=(3,3,32,32)) #Implicitly dtype=trtorch.dtype.float32, format=trtorch.TensorFormat.NCHW
               </p>
              </li>
             </ul>
            </dd>
           </dl>
           <dl class="py attribute">
            <dt id="trtorch.Input.dtype">
             <code class="sig-name descname">
              dtype
             </code>
             <em class="property">
              = &lt;dtype.unknown: 5&gt;
             </em>
             <a class="headerlink" href="#trtorch.Input.dtype" title="Permalink to this definition">
              ¶
             </a>
            </dt>
            <dd>
             <p>
              trtorch.dtype.float32)
             </p>
             <dl class="field-list simple">
              <dt class="field-odd">
               Type
              </dt>
              <dd class="field-odd">
               <p>
                The expected data type of the input tensor (default
               </p>
              </dd>
             </dl>
            </dd>
           </dl>
           <dl class="py attribute">
            <dt id="trtorch.Input.format">
             <code class="sig-name descname">
              format
             </code>
             <em class="property">
              = &lt;TensorFormat.contiguous: 0&gt;
             </em>
             <a class="headerlink" href="#trtorch.Input.format" title="Permalink to this definition">
              ¶
             </a>
            </dt>
            <dd>
             <p>
              trtorch.TensorFormat.NCHW)
             </p>
             <dl class="field-list simple">
              <dt class="field-odd">
               Type
              </dt>
              <dd class="field-odd">
               <p>
                The expected format of the input tensor (default
               </p>
              </dd>
             </dl>
            </dd>
           </dl>
           <dl class="py attribute">
            <dt id="trtorch.Input.shape">
             <code class="sig-name descname">
              shape
             </code>
             <em class="property">
              = None
             </em>
             <a class="headerlink" href="#trtorch.Input.shape" title="Permalink to this definition">
              ¶
             </a>
            </dt>
            <dd>
             <p>
              Either a single Tuple or a dict of tuples defining the input shape. Static shaped inputs will have a single tuple. Dynamic inputs will have a dict of the form
              <code class="docutils literal notranslate">
               <span class="pre">
                {
               </span>
               <span class="pre">
                "min_shape":
               </span>
               <span class="pre">
                Tuple,
               </span>
               <span class="pre">
                "opt_shape":
               </span>
               <span class="pre">
                Tuple,
               </span>
               <span class="pre">
                "max_shape":
               </span>
               <span class="pre">
                Tuple
               </span>
               <span class="pre">
                }
               </span>
              </code>
             </p>
             <dl class="field-list simple">
              <dt class="field-odd">
               Type
              </dt>
              <dd class="field-odd">
               <p>
                (Tuple or Dict)
               </p>
              </dd>
             </dl>
            </dd>
           </dl>
           <dl class="py attribute">
            <dt id="trtorch.Input.shape_mode">
             <code class="sig-name descname">
              shape_mode
             </code>
             <em class="property">
              = None
             </em>
             <a class="headerlink" href="#trtorch.Input.shape_mode" title="Permalink to this definition">
              ¶
             </a>
            </dt>
            <dd>
             <p>
              Is input statically or dynamically shaped
             </p>
             <dl class="field-list simple">
              <dt class="field-odd">
               Type
              </dt>
              <dd class="field-odd">
               <p>
                (trtorch.Input._ShapeMode)
               </p>
              </dd>
             </dl>
            </dd>
           </dl>
          </dd>
         </dl>
         <dl class="py class">
          <dt id="trtorch.Device">
           <em class="property">
            class
           </em>
           <code class="sig-prename descclassname">
            trtorch.
           </code>
           <code class="sig-name descname">
            Device
           </code>
           <span class="sig-paren">
            (
           </span>
           <em class="sig-param">
            <span class="o">
             *
            </span>
            <span class="n">
             args
            </span>
           </em>
           ,
           <em class="sig-param">
            <span class="o">
             **
            </span>
            <span class="n">
             kwargs
            </span>
           </em>
           <span class="sig-paren">
            )
           </span>
           <a class="headerlink" href="#trtorch.Device" title="Permalink to this definition">
            ¶
           </a>
          </dt>
          <dd>
           <p>
            Defines a device that can be used to specify target devices for engines
           </p>
           <dl class="py method">
            <dt id="trtorch.Device.__init__">
             <code class="sig-name descname">
              __init__
             </code>
             <span class="sig-paren">
              (
             </span>
             <em class="sig-param">
              <span class="o">
               *
              </span>
              <span class="n">
               args
              </span>
             </em>
             ,
             <em class="sig-param">
              <span class="o">
               **
              </span>
              <span class="n">
               kwargs
              </span>
             </em>
             <span class="sig-paren">
              )
             </span>
             <a class="headerlink" href="#trtorch.Device.__init__" title="Permalink to this definition">
              ¶
             </a>
            </dt>
            <dd>
             <p>
              __init__ Method for trtorch.Device
             </p>
             <p>
              Device accepts one of a few construction patterns
             </p>
             <dl class="field-list simple">
              <dt class="field-odd">
               Parameters
              </dt>
              <dd class="field-odd">
               <p>
                <strong>
                 spec
                </strong>
                (
                <em>
                 str
                </em>
                ) – String with device spec e.g. “dla:0” for dla, core_id 0
               </p>
              </dd>
              <dt class="field-even">
               Keyword Arguments
              </dt>
              <dd class="field-even">
               <ul class="simple">
                <li>
                 <p>
                  <strong>
                   gpu_id
                  </strong>
                  (
                  <em>
                   int
                  </em>
                  ) – ID of target GPU (will get overrided if dla_core is specified to the GPU managing DLA). If specified, no positional arguments should be provided
                 </p>
                </li>
                <li>
                 <p>
                  <strong>
                   dla_core
                  </strong>
                  (
                  <em>
                   int
                  </em>
                  ) – ID of target DLA core. If specified, no positional arguments should be provided.
                 </p>
                </li>
                <li>
                 <p>
                  <strong>
                   allow_gpu_fallback
                  </strong>
                  (
                  <em>
                   bool
                  </em>
                  ) – Allow TensorRT to schedule operations on GPU if they are not supported on DLA (ignored if device type is not DLA)
                 </p>
                </li>
               </ul>
              </dd>
             </dl>
             <p class="rubric">
              Examples
             </p>
             <ul class="simple">
              <li>
               <p>
                Device(“gpu:1”)
               </p>
              </li>
              <li>
               <p>
                Device(“cuda:1”)
               </p>
              </li>
              <li>
               <p>
                Device(“dla:0”, allow_gpu_fallback=True)
               </p>
              </li>
              <li>
               <p>
                Device(gpu_id=0, dla_core=0, allow_gpu_fallback=True)
               </p>
              </li>
              <li>
               <p>
                Device(dla_core=0, allow_gpu_fallback=True)
               </p>
              </li>
              <li>
               <p>
                Device(gpu_id=1)
               </p>
              </li>
             </ul>
            </dd>
           </dl>
           <dl class="py attribute">
            <dt id="trtorch.Device.allow_gpu_fallback">
             <code class="sig-name descname">
              allow_gpu_fallback
             </code>
             <em class="property">
              = False
             </em>
             <a class="headerlink" href="#trtorch.Device.allow_gpu_fallback" title="Permalink to this definition">
              ¶
             </a>
            </dt>
            <dd>
             <p>
              (bool) Whether falling back to GPU if DLA cannot support an op should be allowed
             </p>
            </dd>
           </dl>
           <dl class="py attribute">
            <dt id="trtorch.Device.device_type">
             <code class="sig-name descname">
              device_type
             </code>
             <em class="property">
              = None
             </em>
             <a class="headerlink" href="#trtorch.Device.device_type" title="Permalink to this definition">
              ¶
             </a>
            </dt>
            <dd>
             <p>
              Target device type (GPU or DLA). Set implicitly based on if dla_core is specified.
             </p>
             <dl class="field-list simple">
              <dt class="field-odd">
               Type
              </dt>
              <dd class="field-odd">
               <p>
                (
                <a class="reference internal" href="#trtorch.DeviceType" title="trtorch.DeviceType">
                 trtorch.DeviceType
                </a>
                )
               </p>
              </dd>
             </dl>
            </dd>
           </dl>
           <dl class="py attribute">
            <dt id="trtorch.Device.dla_core">
             <code class="sig-name descname">
              dla_core
             </code>
             <em class="property">
              = -1
             </em>
             <a class="headerlink" href="#trtorch.Device.dla_core" title="Permalink to this definition">
              ¶
             </a>
            </dt>
            <dd>
             <p>
              (int) Core ID for target DLA core
             </p>
            </dd>
           </dl>
           <dl class="py attribute">
            <dt id="trtorch.Device.gpu_id">
             <code class="sig-name descname">
              gpu_id
             </code>
             <em class="property">
              = -1
             </em>
             <a class="headerlink" href="#trtorch.Device.gpu_id" title="Permalink to this definition">
              ¶
             </a>
            </dt>
            <dd>
             <p>
              (int) Device ID for target GPU
             </p>
            </dd>
           </dl>
          </dd>
         </dl>
        </section>
        <section id="enums">
         <h2 id="enums">
          Enums
          <a class="headerlink" href="#enums" title="Permalink to this headline">
           ¶
          </a>
         </h2>
         <dl class="py class">
          <dt id="trtorch.dtype">
           <em class="property">
            class
           </em>
           <code class="sig-prename descclassname">
            trtorch.
           </code>
           <code class="sig-name descname">
            dtype
           </code>
           <a class="headerlink" href="#trtorch.dtype" title="Permalink to this definition">
            ¶
           </a>
          </dt>
          <dd>
           <p>
            Enum to specifiy operating precision for engine execution
           </p>
           <p>
            Members:
           </p>
           <blockquote>
            <div>
             <p>
              float : 32 bit floating point number
             </p>
             <p>
              float32 : 32 bit floating point number
             </p>
             <p>
              half : 16 bit floating point number
             </p>
             <p>
              float16 : 16 bit floating point number
             </p>
             <p>
              int8 : 8 bit integer number
             </p>
             <p>
              int32 : 32 bit integer number
             </p>
             <p>
              bool : Boolean value
             </p>
             <p>
              unknown : Unknown data type
             </p>
            </div>
           </blockquote>
          </dd>
         </dl>
         <dl class="py class">
          <dt id="trtorch.DeviceType">
           <em class="property">
            class
           </em>
           <code class="sig-prename descclassname">
            trtorch.
           </code>
           <code class="sig-name descname">
            DeviceType
           </code>
           <a class="headerlink" href="#trtorch.DeviceType" title="Permalink to this definition">
            ¶
           </a>
          </dt>
          <dd>
           <p>
            Enum to specify device kinds to build TensorRT engines for
           </p>
           <p>
            Members:
           </p>
           <blockquote>
            <div>
             <p>
              GPU : Specify using GPU to execute TensorRT Engine
             </p>
             <p>
              DLA : Specify using DLA to execute TensorRT Engine (Jetson Only)
             </p>
            </div>
           </blockquote>
          </dd>
         </dl>
         <dl class="py class">
          <dt id="trtorch.EngineCapability">
           <em class="property">
            class
           </em>
           <code class="sig-prename descclassname">
            trtorch.
           </code>
           <code class="sig-name descname">
            EngineCapability
           </code>
           <a class="headerlink" href="#trtorch.EngineCapability" title="Permalink to this definition">
            ¶
           </a>
          </dt>
          <dd>
           <p>
            Enum to specify engine capability settings (selections of kernels to meet safety requirements)
           </p>
           <p>
            Members:
           </p>
           <blockquote>
            <div>
             <p>
              safe_gpu : Use safety GPU kernels only
             </p>
             <p>
              safe_dla : Use safety DLA kernels only
             </p>
             <p>
              default : Use default behavior
             </p>
            </div>
           </blockquote>
          </dd>
         </dl>
         <dl class="py class">
          <dt id="trtorch.TensorFormat">
           <em class="property">
            class
           </em>
           <code class="sig-prename descclassname">
            trtorch.
           </code>
           <code class="sig-name descname">
            TensorFormat
           </code>
           <a class="headerlink" href="#trtorch.TensorFormat" title="Permalink to this definition">
            ¶
           </a>
          </dt>
          <dd>
           <p>
            Enum to specifiy the memory layout of tensors
           </p>
           <p>
            Members:
           </p>
           <blockquote>
            <div>
             <p>
              contiguous : Contiguous memory layout (NCHW / Linear)
             </p>
             <p>
              channel_last : Channel last memory layout (NHWC)
             </p>
            </div>
           </blockquote>
          </dd>
         </dl>
        </section>
        <section id="submodules">
         <h2 id="submodules">
          Submodules
          <a class="headerlink" href="#submodules" title="Permalink to this headline">
           ¶
          </a>
         </h2>
         <div class="toctree-wrapper compound">
          <ul>
           <li class="toctree-l1">
            <a class="reference internal" href="logging.html">
             trtorch.logging
            </a>
           </li>
          </ul>
         </div>
        </section>
       </section>
      </article>
     </div>
    </div>
   </main>
  </div>
  <footer class="md-footer">
   <div class="md-footer-nav">
    <nav class="md-footer-nav__inner md-grid">
     <a class="md-flex md-footer-nav__link md-footer-nav__link--prev" href="../_notebooks/vgg-qat.html" rel="prev" title="Deploying Quantization Aware Trained models in INT8 using TRTorch">
      <div class="md-flex__cell md-flex__cell--shrink">
       <i class="md-icon md-icon--arrow-back md-footer-nav__button">
       </i>
      </div>
      <div class="md-flex__cell md-flex__cell--stretch md-footer-nav__title">
       <span class="md-flex__ellipsis">
        <span class="md-footer-nav__direction">
         Previous
        </span>
        Deploying Quantization Aware Trained models in INT8 using TRTorch
       </span>
      </div>
     </a>
     <a class="md-flex md-footer-nav__link md-footer-nav__link--next" href="logging.html" rel="next" title="trtorch.logging">
      <div class="md-flex__cell md-flex__cell--stretch md-footer-nav__title">
       <span class="md-flex__ellipsis">
        <span class="md-footer-nav__direction">
         Next
        </span>
        trtorch.logging
       </span>
      </div>
      <div class="md-flex__cell md-flex__cell--shrink">
       <i class="md-icon md-icon--arrow-forward md-footer-nav__button">
       </i>
      </div>
     </a>
    </nav>
   </div>
   <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
     <div class="md-footer-copyright">
      <div class="md-footer-copyright__highlight">
       © Copyright 2021, NVIDIA Corporation.
      </div>
      Created using
      <a href="http://www.sphinx-doc.org/">
       Sphinx
      </a>
      3.1.2.
             and
      <a href="https://github.com/bashtage/sphinx-material/">
       Material for
              Sphinx
      </a>
     </div>
    </div>
   </div>
  </footer>
  <script src="../_static/javascripts/application.js">
  </script>
  <script>
   app.initialize({version: "1.0.4", url: {base: ".."}})
  </script>
 </body>
</html>